{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cb3cfe3",
   "metadata": {},
   "source": [
    "# Example of using SpecialtyInsurance Simulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5ae1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Set Simulation Parameters\n",
    "\n",
    "import os\n",
    "from logger.arguments import get_arguments\n",
    "\n",
    "# Read arguments from logger.arguments\n",
    "sim_args, manager_args, broker_args, syndicate_args, reinsurancefirm_args, shareholder_args, risk_args = get_arguments()\n",
    "\n",
    "# Reset arguments\n",
    "sim_args[\"max_time\"] = 30   # Simulation time span unit day\n",
    "manager_args[\"lead_top_k\"] = 3   # Number of syndicates competing for the lead quote\n",
    "manager_args[\"follow_top_k\"] = 2   # Number of syndicates following the lead strategy\n",
    "broker_args[\"num_brokers\"] = 1   # Number of brokers in the insurance market\n",
    "syndicate_args[\"num_syndicates\"] = 3   # Number of syndicates in the insurance market\n",
    "shareholder_args[\"num_shareholders\"] = 1   # Number of shareholders in the insurance market\n",
    "risk_args[\"num_risks\"] = 1  # Number of risks\n",
    "risk_args[\"num_categories\"] = 4  # Number of risk categories\n",
    "\n",
    "# No reinsurance mechanism included in this stage\n",
    "with_reinsurance = False   \n",
    "\n",
    "# Nomber of risk models loaded to all syndicates\n",
    "num_risk_models = 1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b158de5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catastrophe starts at time 29\n"
     ]
    }
   ],
   "source": [
    "### 2. Generate Catastrophes\n",
    "\n",
    "from environment.risk_generator import RiskGenerator\n",
    "\n",
    "# Create catastrophe list and catastrophe configurations\n",
    "catastrophes, risk_model_configs = RiskGenerator(num_risk_models, sim_args, risk_args).generate_risks()\n",
    "print(\"catastrophe starts at time\", catastrophes[0].get(\"risk_start_time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f8ba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'broker_id': '0', 'broker_risk': [], 'broker_quote': []}\n",
      "{'syndicate_id': '0', 'initial_capital': 10000000, 'current_capital': 10000000, 'premium_internal_weight': 0.5, 'interest_rate': 0.001, 'play_leader_in_contracts': [], 'play_follower_in_contracts': [], 'loss_experiency_weight': 0.2, 'volatility_weight': 0, 'underwriter_markup_recency_weight': 0.2, 'upper_premium_limit': 1.2, 'lower_premium_limit': 0.85, 'premium_reserve_ratio': 0.5, 'minimum_capital_reserve_ratio': 1, 'maximum_scaling_factor': 1, 'market_entry_probability': 0.3, 'exit_capital_threshold': 0.6, 'exit_time_limit': 24, 'premium_sensitivity': 5, 'acceptance_threshold_friction': 0.9}\n",
      "{'syndicate_id': '1', 'initial_capital': 10000000, 'current_capital': 10000000, 'premium_internal_weight': 0.5, 'interest_rate': 0.001, 'play_leader_in_contracts': [], 'play_follower_in_contracts': [], 'loss_experiency_weight': 0.2, 'volatility_weight': 0, 'underwriter_markup_recency_weight': 0.2, 'upper_premium_limit': 1.2, 'lower_premium_limit': 0.85, 'premium_reserve_ratio': 0.5, 'minimum_capital_reserve_ratio': 1, 'maximum_scaling_factor': 1, 'market_entry_probability': 0.3, 'exit_capital_threshold': 0.6, 'exit_time_limit': 24, 'premium_sensitivity': 5, 'acceptance_threshold_friction': 0.9}\n",
      "{'syndicate_id': '2', 'initial_capital': 10000000, 'current_capital': 10000000, 'premium_internal_weight': 0.5, 'interest_rate': 0.001, 'play_leader_in_contracts': [], 'play_follower_in_contracts': [], 'loss_experiency_weight': 0.2, 'volatility_weight': 0, 'underwriter_markup_recency_weight': 0.2, 'upper_premium_limit': 1.2, 'lower_premium_limit': 0.85, 'premium_reserve_ratio': 0.5, 'minimum_capital_reserve_ratio': 1, 'maximum_scaling_factor': 1, 'market_entry_probability': 0.3, 'exit_capital_threshold': 0.6, 'exit_time_limit': 24, 'premium_sensitivity': 5, 'acceptance_threshold_friction': 0.9}\n"
     ]
    }
   ],
   "source": [
    "### 3. Generate Insurance Market\n",
    "\n",
    "from environment.market_generator import MarketGenerator\n",
    "\n",
    "# Create lists of brokers, syndicates, reinsurancefirms, and shareholders\n",
    "brokers, syndicates, reinsurancefirms, shareholders = MarketGenerator(with_reinsurance, \n",
    "                                                                      num_risk_models, \n",
    "                                                                      sim_args, \n",
    "                                                                      broker_args, \n",
    "                                                                      syndicate_args, \n",
    "                                                                      reinsurancefirm_args, \n",
    "                                                                      shareholder_args, \n",
    "                                                                      risk_model_configs).generate_agents()\n",
    "for broker_id in range(len(brokers)):\n",
    "    print(brokers[broker_id].data())\n",
    "for syndicate_id in range(len(syndicates)):\n",
    "    print(syndicates[syndicate_id].data())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfc0a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_id: 0 broker_id: 0 risk_start_time: 0 risk_end_time: 360 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 1 broker_id: 0 risk_start_time: 1 risk_end_time: 361 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 2 broker_id: 0 risk_start_time: 2 risk_end_time: 362 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 3 broker_id: 0 risk_start_time: 3 risk_end_time: 363 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 4 broker_id: 0 risk_start_time: 4 risk_end_time: 364 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 5 broker_id: 0 risk_start_time: 5 risk_end_time: 365 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 6 broker_id: 0 risk_start_time: 6 risk_end_time: 366 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 7 broker_id: 0 risk_start_time: 7 risk_end_time: 367 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 8 broker_id: 0 risk_start_time: 8 risk_end_time: 368 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 9 broker_id: 0 risk_start_time: 9 risk_end_time: 369 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 10 broker_id: 0 risk_start_time: 10 risk_end_time: 370 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 11 broker_id: 0 risk_start_time: 11 risk_end_time: 371 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 12 broker_id: 0 risk_start_time: 12 risk_end_time: 372 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 13 broker_id: 0 risk_start_time: 13 risk_end_time: 373 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 14 broker_id: 0 risk_start_time: 14 risk_end_time: 374 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 15 broker_id: 0 risk_start_time: 15 risk_end_time: 375 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 16 broker_id: 0 risk_start_time: 16 risk_end_time: 376 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 17 broker_id: 0 risk_start_time: 17 risk_end_time: 377 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 18 broker_id: 0 risk_start_time: 18 risk_end_time: 378 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 19 broker_id: 0 risk_start_time: 19 risk_end_time: 379 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 20 broker_id: 0 risk_start_time: 20 risk_end_time: 380 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 21 broker_id: 0 risk_start_time: 21 risk_end_time: 381 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 22 broker_id: 0 risk_start_time: 22 risk_end_time: 382 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 23 broker_id: 0 risk_start_time: 23 risk_end_time: 383 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 24 broker_id: 0 risk_start_time: 24 risk_end_time: 384 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 25 broker_id: 0 risk_start_time: 25 risk_end_time: 385 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 26 broker_id: 0 risk_start_time: 26 risk_end_time: 386 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 27 broker_id: 0 risk_start_time: 27 risk_end_time: 387 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 28 broker_id: 0 risk_start_time: 28 risk_end_time: 388 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 29 broker_id: 0 risk_start_time: 29 risk_end_time: 389 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 30 broker_id: 0 risk_start_time: 30 risk_end_time: 390 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n",
      "risk_id: 31 broker_id: 0 risk_start_time: 31 risk_end_time: 391 risk_factor: 0.473771039728008 risk_category: 1 risk_value: 1000.0\n"
     ]
    }
   ],
   "source": [
    "### 4. Input risk from broker\n",
    "\n",
    "from environment.event_generator import EventGenerator\n",
    "\n",
    "current_time = 0\n",
    "broker_risk_events = EventGenerator(risk_model_configs).generate_risk_events(sim_args, brokers, catastrophes)\n",
    "\n",
    "for i in range(len(broker_risk_events)):\n",
    "    print(\"risk_id:\", broker_risk_events[i].risk_id, \"broker_id:\", broker_risk_events[i].broker_id, \"risk_start_time:\", broker_risk_events[i].risk_start_time,\n",
    "         \"risk_end_time:\", broker_risk_events[i].risk_end_time, \"risk_factor:\", broker_risk_events[i].risk_factor,\n",
    "         \"risk_category:\", broker_risk_events[i].risk_category, \"risk_value:\", broker_risk_events[i].risk_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db3c303-e353-4276-bff4-86e0e42e0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import warnings\n",
    "from environment.event.add_catastrophe import AddCatastropheEvent\n",
    "from environment.event.add_attritionalloss import AddAttritionalLossEvent\n",
    "from environment.event.add_risk import AddRiskEvent\n",
    "from environment.event.add_premium import AddPremiumEvent\n",
    "from environment.event.add_claim import AddClaimEvent\n",
    "import numpy as np\n",
    "from environment.market import NoReinsurance_RiskOne, NoReinsurance_RiskFour, Reinsurance_RiskOne, Reinsurance_RiskFour\n",
    "from manager.event_handler import EventHandler\n",
    "\n",
    "class MarketManager:\n",
    "    \"\"\"\n",
    "    Manage and evolve the market.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, maxstep, manager_args, brokers, syndicates, reinsurancefirms, shareholders, risks, risk_model_configs, with_reinsurance, num_risk_models, broker_risk_events, event_handler, logger = None, time = 0):\n",
    "        self.maxstep = maxstep\n",
    "        self.manager_args = manager_args\n",
    "        self.brokers = brokers\n",
    "        self.syndicates = syndicates\n",
    "        self.reinsurancefirms = reinsurancefirms\n",
    "        self.shareholders = shareholders\n",
    "        self.risks = risks\n",
    "        self.risk_model_configs = risk_model_configs\n",
    "        self.with_reinsurance = with_reinsurance\n",
    "        self.num_risk_models = num_risk_models\n",
    "        #self.catastrophe_events = catastrophe_events\n",
    "        #self.attritional_loss_events = attritional_loss_events\n",
    "        self.broker_risk_events = broker_risk_events\n",
    "        #self.broker_premium_events = broker_premium_events\n",
    "        #self.broker_claim_events = broker_claim_events\n",
    "        self.event_handler = event_handler\n",
    "\n",
    "        self.market = NoReinsurance_RiskOne(time, self.maxstep, self.manager_args, self.brokers, self.syndicates, self.shareholders, self.risks, self.risk_model_configs, self.broker_risk_events)\n",
    "\n",
    "        self.min_step_time = 1  # Day Event\n",
    "\n",
    "        self.actions_to_apply = []\n",
    "        # For logging keep track of all Actions ever received and whether they were accepted or refused by the manager\n",
    "        self.actions_accepted = {}\n",
    "        self.actions_refused = {}\n",
    "\n",
    "        # Logging\n",
    "        self.logger = logger\n",
    "        if self.logger is not None:\n",
    "            self.logger._store_metadata(\n",
    "                self.market.time, self.market.brokers, self.market.syndicates, self.market.reinsurancefirms, self.market.shareholders, self.event_handler\n",
    "            )\n",
    "\n",
    "    def get_time_to_next_event(self, event_type):\n",
    "        \"\"\"\n",
    "        Get time to the next Event.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        event_type: List[Type[Event]]\n",
    "            Optional list of Event types to restrict to (i.e., skip over Event types not in the list).\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        float\n",
    "           Time [day] until the next upcoming Event.\n",
    "        \"\"\"\n",
    "\n",
    "        # Sort upcoming events by start_time\n",
    "        #upcoming_catastrophe_events = list(self.event_handler.upcoming_catastrophe.values()) + list(self.event_handler.ongoing_catastrophe.values())\n",
    "        #upcoming_catastrophe_events.sort()\n",
    "        #upcoming_attritional_loss_events = list(self.event_handler.upcoming_attritional_loss.values()) + list(self.event_handler.ongoing_attritional_loss.values())\n",
    "        #upcoming_attritional_loss_events.sort()\n",
    "        upcoming_broker_risk_events = list(self.event_handler.upcoming_broker_risk.values()) + list(self.event_handler.ongoing_broker_risk.values())\n",
    "        upcoming_broker_risk_events.sort()\n",
    "        #upcoming_broker_premium_events = list(self.event_handler.upcoming_broker_premium.values()) + list(self.event_handler.ongoing_broker_premium.values())\n",
    "        #upcoming_broker_premium_events.sort()\n",
    "        #upcoming_broker_claim_events = list(self.event_handler.upcoming_broker_claim.values()) + list(self.event_handler.ongoing_broker_claim.values())\n",
    "        #upcoming_broker_claim_events.sort()\n",
    "\n",
    "        # Check if there are any upcoming events left\n",
    "        #if ((len(upcoming_catastrophe_events) == 0) and (len(upcoming_attritional_loss_events) == 0) and (len(upcoming_broker_risk_events) == 0)\n",
    "            #and (len(upcoming_broker_premium_events) == 0) and (len(upcoming_broker_claim_events) == 0)):\n",
    "            #return None\n",
    "\n",
    "        # Get time to next event\n",
    "        #next_catastrophe_event = upcoming_catastrophe_events[0]\n",
    "        #time_to_next_catastrophe_event = next_catastrophe_event.start_time - self.market.time\n",
    "        #next_attritional_loss_event = upcoming_attritional_loss_events[0]\n",
    "        #time_to_next_attritional_loss_event = next_attritional_loss_event.start_time - self.market.time\n",
    "        next_broker_risk_event = upcoming_broker_risk_events[0]\n",
    "        time_to_next_broker_risk_event = next_broker_risk_event.start_time - self.market.time\n",
    "        #next_broker_premium_event = upcoming_broker_premium_events[0]\n",
    "        #time_to_next_broker_premium_event = next_broker_premium_event.start_time - self.market.time\n",
    "        #next_broker_claim_event = upcoming_broker_claim_events[0]\n",
    "        #time_to_next_broker_claim_event = next_broker_claim_event.start_time - self.market.time\n",
    "\n",
    "        #return time_to_next_catastrophe_event, time_to_next_attritional_loss_event, time_to_next_broker_risk_event, time_to_next_broker_premium_event, time_to_next_broker_claim_event\n",
    "        return time_to_next_broker_risk_event\n",
    "\n",
    "    def evolve_action_market(self, starting_broker_risk, step_time):\n",
    "        \"\"\"\n",
    "        Evolve the syndicate, broker, risk in the market for step_time [day].\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        starting_broker_risk: AddRiskEvent\n",
    "            The current risk event.\n",
    "        step_time: float\n",
    "            Amount of time in days to evolve the Market for.\n",
    "        \"\"\"\n",
    "\n",
    "        # Update the status of brokers and syndicates in the market\n",
    "        risk_id = starting_broker_risk.risk_id\n",
    "        broker_id = starting_broker_risk.broker_id\n",
    "        risks = {\"risk_id\": starting_broker_risk.risk_id,\n",
    "                \"risk_start_time\": starting_broker_risk.risk_start_time,\n",
    "                \"risk_factor\": starting_broker_risk.risk_factor,\n",
    "                \"risk_category\": starting_broker_risk.risk_category,\n",
    "                \"risk_value\": starting_broker_risk.risk_value}\n",
    "        if len(self.actions_to_apply) > 0:\n",
    "            lead_syndicate_id = self.actions_to_apply[0].syndicate\n",
    "            follow_syndicates_id = [self.actions_to_apply[i].syndicate for i in range(1,len(self.actions_to_apply))]\n",
    "            premium = starting_broker_risk.risk_value # TODO: will be changed in the future\n",
    "            self.market.brokers[int(broker_id)].add_contract(risks, lead_syndicate_id, follow_syndicates_id, premium)\n",
    "            self.market.syndicates[int(lead_syndicate_id)].add_leader(risks, self.actions_to_apply[0].line_size, premium)\n",
    "            self.market.syndicates[int(lead_syndicate_id)].add_contract(risks, broker_id, premium)\n",
    "            for sy in range(len(follow_syndicates_id)):\n",
    "                self.market.syndicates[int(follow_syndicates_id[sy])].add_follower(risks, self.actions_to_apply[1+sy].line_size, premium)\n",
    "                self.market.syndicates[int(follow_syndicates_id[sy])].add_contract(risks, broker_id, premium)\n",
    "        else:\n",
    "            self.market.brokers[0].not_underwritten_risk(risks)\n",
    "\n",
    "    def evolve(self, step_time):\n",
    "\n",
    "        # Storage for all the syndicates' status\n",
    "        syndicates_status = {}\n",
    "\n",
    "        # The time the market will have after being evolved\n",
    "        market_start_time = self.market.time\n",
    "        market_end_time = self.market.time + step_time\n",
    "\n",
    "        #upcoming_catastrophe = [\n",
    "            #e.risk_id for e in self.event_handler.upcoming_catastrophe.values() if isinstance(e, AddCatastropheEvent)\n",
    "        #]\n",
    "\n",
    "        #upcoming_attritional_loss = [\n",
    "            #e.risk_id for e in self.event_handler.upcoming_attritional_loss.values() if isinstance(e, AddAttritionalLossEvent)\n",
    "        #]\n",
    "\n",
    "        upcoming_broker_risk = [\n",
    "            e.risk_id for e in self.event_handler.upcoming_broker_risk.values() if isinstance(e, AddRiskEvent)\n",
    "        ]\n",
    "\n",
    "        #upcoming_broker_premium = [\n",
    "            #e.risk_id for e in self.event_handler.upcoming_broker_premium.values() if isinstance(e, AddPremiumEvent)\n",
    "        #]\n",
    "\n",
    "        #upcoming_broker_claim = [\n",
    "            #e.risk_id for e in self.event_handler.upcoming_broker_claim.values() if isinstance(e, AddClaimEvent)\n",
    "        #]\n",
    "\n",
    "        # Enact the events\n",
    "        self.market = self.event_handler.forward(self.market, step_time)\n",
    "\n",
    "        # Track any newly-added events\n",
    "        #newly_added_catastrophe_events = {\n",
    "            #e.risk_id: e.risk_start_time\n",
    "            #for e in self.event_handler.upcoming_catastrophe.values()\n",
    "            #if isinstance(e, AddCatastropheEvent) and (e.risk_id in upcoming_catastrophe)\n",
    "        #}\n",
    "\n",
    "        #newly_added_attritional_loss_events = {\n",
    "            #e.risk_id: e.risk_start_time\n",
    "            #for e in self.event_handler.completed_attritional_loss.values()\n",
    "            #if isinstance(e, AddAttritionalLossEvent) and (e.risk_id in upcoming_attritional_loss)\n",
    "        #}\n",
    "\n",
    "        newly_added_broker_risk_events = {\n",
    "            e.risk_id: e.risk_start_time\n",
    "            for e in self.event_handler.completed_broker_risk.values()\n",
    "            if isinstance(e, AddRiskEvent) and (e.risk_id in upcoming_broker_risk)\n",
    "        }\n",
    "\n",
    "        #newly_added_broker_premium_events = {\n",
    "            #e.risk_id: e.risk_start_time\n",
    "            #for e in self.event_handler.completed_broker_premium.values()\n",
    "            #if isinstance(e, AddPremiumEvent) and (e.risk_id in upcoming_broker_premium)\n",
    "        #}\n",
    "\n",
    "        #newly_added_broker_claim_events = {\n",
    "            #e.risk_id: e.risk_start_time\n",
    "            #for e in self.event_handler.completed_broker_claim.values()\n",
    "            #if isinstance(e, AddClaimEvent) and (e.risk_id in upcoming_broker_claim)\n",
    "        #}\n",
    "\n",
    "        \n",
    "        #catastrophe_event_start_times = np.array(\n",
    "            #[\n",
    "            #    newly_added_catastrophe_events.get(risk_id)\n",
    "            #    for risk_id in upcoming_catastrophe\n",
    "            #    if newly_added_catastrophe_events.get(risk_id) != None\n",
    "            #]\n",
    "        #)\n",
    "\n",
    "        #attritional_loss_event_start_times = np.array(\n",
    "            #[\n",
    "            #    newly_added_attritional_loss_events.get(risk_id)\n",
    "            #    for risk_id in upcoming_attritional_loss\n",
    "            #    if newly_added_attritional_loss_events.get(risk_id) != None\n",
    "            #]\n",
    "        #)\n",
    "\n",
    "        broker_risk_event_start_times = np.array(\n",
    "            [\n",
    "                newly_added_broker_risk_events.get(risk_id)\n",
    "                for risk_id in upcoming_broker_risk\n",
    "                if newly_added_broker_risk_events.get(risk_id) != None\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        #broker_premium_event_start_times = np.array(\n",
    "            #[\n",
    "            #    newly_added_broker_premium_events.get(risk_id)\n",
    "            #    for risk_id in upcoming_broker_premium\n",
    "            #    if newly_added_broker_premium_events.get(risk_id) != None\n",
    "            #]\n",
    "        #)\n",
    "\n",
    "        #broker_claim_event_start_times = np.array(\n",
    "            #[\n",
    "            #    newly_added_broker_claim_events.get(risk_id)\n",
    "            #    for risk_id in upcoming_broker_claim\n",
    "            #    if newly_added_broker_claim_events.get(risk_id) != None\n",
    "            #]\n",
    "        #)\n",
    "\n",
    "        #event_start_times = np.concatenate((catastrophe_event_start_times,\n",
    "        #                                    attritional_loss_event_start_times,\n",
    "        #                                    broker_risk_event_start_times,\n",
    "        #                                    broker_premium_event_start_times,\n",
    "        #                                    broker_claim_event_start_times))\n",
    "\n",
    "        # Get the unique start times and sort\n",
    "        sorted_unique_start_times = np.sort(np.unique(broker_risk_event_start_times))\n",
    "\n",
    "        # Update all the agents, run the event at the same start time\n",
    "        for start_time in sorted_unique_start_times:\n",
    "            # Move along the market's time\n",
    "            self.market.time = start_time\n",
    "\n",
    "            # Get all the events starting at this time\n",
    "            #starting_catastrophe = None\n",
    "            #starting_attritional_loss = None\n",
    "            starting_broker_risk = None\n",
    "            #starting_broker_premium = None\n",
    "            #starting_broker_claim = None\n",
    "            #for i in range(len(self.catastrophe_events)):\n",
    "               # if self.catastrophe_events[i].risk_start_time == start_time:\n",
    "                #    starting_catastrophe = self.catastrophe_events[i]\n",
    "            #for i in range(len(self.attritional_loss_events)):\n",
    "               # if self.attritional_loss_events[i].risk_start_time == start_time:\n",
    "                #    starting_attritional_loss = self.attritional_loss_events[i]\n",
    "            for i in range(len(self.broker_risk_events)):\n",
    "                if self.broker_risk_events[i].risk_start_time == start_time:\n",
    "                    starting_broker_risk = self.broker_risk_events[i]\n",
    "           # for i in range(len(self.broker_premium_events)):\n",
    "                #if self.broker_premium_events[i].risk_start_time == start_time:\n",
    "                #    starting_broker_premium = self.broker_premium_events[i]\n",
    "            #for i in range(len(self.broker_claim_events)):\n",
    "                #if self.broker_claim_events[i].risk_start_time == start_time:\n",
    "                 #   starting_broker_claim = self.broker_claim_events[i]\n",
    "\n",
    "            # Calculate the time they should proceed for\n",
    "            proceed_time = market_end_time - start_time\n",
    "\n",
    "            # edge case: the aircraft wants to move at the time env.time + step_time,\n",
    "            # in this case nothing needs to be done\n",
    "            if proceed_time == 0:\n",
    "                continue\n",
    "\n",
    "            # Move along the corresponding syndicates\n",
    "            self.evolve_action_market(starting_broker_risk, proceed_time)\n",
    "\n",
    "            # Empty all the actions to apply to syndicates\n",
    "            self.actions_to_apply = []\n",
    "\n",
    "        self.market.time = market_end_time\n",
    "\n",
    "        return self.market\n",
    "\n",
    "    def receive_actions(self, actions):\n",
    "\n",
    "        # Choose the leader and save its action, the first syndicate with the highest line size wins \n",
    "        # TODO: will add selection algorithm in the future\n",
    "        sum_line_size = 0\n",
    "        for sy in range(len(self.market.syndicates)):\n",
    "            sum_line_size += actions[sy].line_size\n",
    "        \n",
    "        if sum_line_size < 1:\n",
    "            # Refuse the quote TODO: will add refuse in the future, action space from 0.0 to 0.9\n",
    "            accept_actions = []\n",
    "        else:\n",
    "            # Accept the quote\n",
    "            accept_actions = []\n",
    "            # Find the leader\n",
    "            line_size = 0\n",
    "            syndicate_id = 0\n",
    "            syndicate_list = []\n",
    "            for sy in range(len(self.market.syndicates)):\n",
    "                if actions[sy].line_size > line_size:\n",
    "                    line_size = actions[sy].line_size\n",
    "                    syndicate_id = sy\n",
    "            syndicate_list.append(syndicate_id)\n",
    "            accept_actions.append(actions[syndicate_id])\n",
    "            # Assign line size to the rest syndicates, FIFO\n",
    "            rest_line_size = 1 - line_size\n",
    "            while rest_line_size > 0:\n",
    "                for sy in range(len(self.market.syndicates)):\n",
    "                    if sy not in syndicate_list:\n",
    "                        if actions[sy].line_size > rest_line_size:\n",
    "                            actions[sy].line_size = rest_line_size\n",
    "                            accept_actions.append(actions[sy])\n",
    "                            syndicate_list.append(sy)\n",
    "                            rest_line_size -= actions[sy].line_size\n",
    "                            break\n",
    "                        else:\n",
    "                            rest_line_size -= actions[sy].line_size\n",
    "                            accept_actions.append(actions[sy])\n",
    "                            syndicate_list.append(sy)\n",
    "        # Save Actions to issue\n",
    "        self.actions_to_apply = accept_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec86fe5-5568-43d0-bfe5-75632f83bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. Create Multi-agent Environment to get access to the market performance\n",
    "\n",
    "import gym\n",
    "from environment.environment import SpecialtyInsuranceMarketEnv\n",
    "from environment.event_generator import EventGenerator\n",
    "from manager.ai_model.action import Action\n",
    "from manager import EventHandler\n",
    "\n",
    "class MultiAgentBasedModel(SpecialtyInsuranceMarketEnv):\n",
    "\n",
    "    def __init__(self, sim_args, manager_args, brokers, syndicates, reinsurancefirms, shareholders, catastrophes, risk_model_configs, with_reinsurance, num_risk_models, dt = 1):\n",
    "\n",
    "        self.sim_args = sim_args\n",
    "        self.maxstep = self.sim_args[\"max_time\"]\n",
    "        self.manager_args = manager_args\n",
    "        self.brokers = brokers\n",
    "        self.initial_brokers = brokers\n",
    "        self.syndicates = syndicates\n",
    "        self.initial_syndicates = syndicates\n",
    "        self.reinsurancefirms = reinsurancefirms\n",
    "        self.initial_reinsurancefirms = reinsurancefirms\n",
    "        self.shareholders = shareholders\n",
    "        self.initial_shareholders = shareholders\n",
    "        self.risks = catastrophes\n",
    "        self.initial_risks = catastrophes\n",
    "        self.risk_model_configs = risk_model_configs\n",
    "        self.with_reinsurance = with_reinsurance\n",
    "        self.num_risk_models = num_risk_models\n",
    "        self.dt = dt\n",
    "        self.mm = None\n",
    "        self.event_handler = None\n",
    "\n",
    "        # Active syndicate list\n",
    "        self.syndicate_active_list = []\n",
    "        # Initialise events, actions, and states \n",
    "        self.broker_risk_events = []\n",
    "        self.action_map_dict = {}\n",
    "        self.state_encoder_dict = {}\n",
    "\n",
    "        # Define Action Space, Define Observation Space\n",
    "        self.n = len(self.syndicates)\n",
    "        self.agents = {self.syndicates[i].syndicate_id for i in range(self.n)} \n",
    "        self._agent_ids = set(self.agents)\n",
    "        self.dones = set()\n",
    "        self._spaces_in_preferred_format = True\n",
    "        self.observation_space = gym.spaces.Dict({\n",
    "            self.syndicates[i].syndicate_id: gym.spaces.Box(low=np.array([-1000000,-1000000,-1000000,-1000000,-1000000,-1000000]), \n",
    "                                                     high=np.array([1000000,1000000,3000000,3000000,3000000,3000000]), dtype = np.float32) for i in range(self.n)\n",
    "        })\n",
    "        self.action_space = gym.spaces.Dict({\n",
    "            self.syndicates[i].syndicate_id: gym.spaces.Box(0.5, 0.9, dtype = np.float32) for i in range(self.n)})\n",
    "\n",
    "        super(MultiAgentBasedModel, self).__init__(sim_args = self.sim_args, \n",
    "                                                   manager_args = self.manager_args , \n",
    "                                                   brokers = self.brokers, \n",
    "                                                   syndicates = self.syndicates, \n",
    "                                                   reinsurancefirms = self.reinsurancefirms, \n",
    "                                                   shareholders = self.shareholders, \n",
    "                                                   risks = self.risks, \n",
    "                                                   risk_model_configs = self.risk_model_configs, \n",
    "                                                   with_reinsurance = self.with_reinsurance, \n",
    "                                                   num_risk_models = self.num_risk_models,\n",
    "                                                   dt = 1)\n",
    "        # Reset the environmnet\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed = None, options = None):\n",
    "        super().reset(seed = seed)\n",
    "        \n",
    "        # Reset the environment to an initial state\n",
    "        self.brokers = self.initial_brokers\n",
    "        self.syndicates = self.initial_syndicates\n",
    "        self.reinsurancefirms = self.initial_reinsurancefirms\n",
    "        self.shareholders = self.initial_shareholders\n",
    "        self.risks = self.initial_risks\n",
    "        # Broker risk event daily: broker generate risk according to poisson distribution\n",
    "        self.broker_risk_events = broker_risk_events\n",
    "        self.event_handler = EventHandler(self.maxstep, self.broker_risk_events)\n",
    "        # Initiate market manager\n",
    "        self.mm = MarketManager(self.maxstep, self.manager_args, self.brokers, self.syndicates, self.reinsurancefirms, self.shareholders, self.risks, self.risk_model_configs, self.with_reinsurance, self.num_risk_models, self.broker_risk_events, self.event_handler)\n",
    "        #self.mm.evolve(self.dt)\n",
    "        \n",
    "        # Set per syndicate active status and build status list\n",
    "        self.syndicate_active_list = []   # Store syndicates currently in the market\n",
    "        for sy in range(len(self.mm.market.syndicates)):\n",
    "            if self.mm.market.syndicates[sy].status == True:\n",
    "                self.syndicate_active_list.append(self.mm.market.syndicates[sy].syndicate_id)\n",
    "\n",
    "        # Create action map and state list\n",
    "        info_dict = {}\n",
    "        for sy in range(len(self.mm.market.syndicates)):\n",
    "            self.action_map_dict[self.mm.market.syndicates[sy].syndicate_id] = self.action_map_creator(self.mm.market.syndicates[sy], 0)\n",
    "            self.state_encoder_dict[self.mm.market.syndicates[sy].syndicate_id] = self.state_encoder(self.mm.market.syndicates[sy].syndicate_id)\n",
    "            info_dict[self.mm.market.syndicates[sy].syndicate_id] = None\n",
    "\n",
    "        # Initiate time step\n",
    "        self.timestep = -1\n",
    "        self.step_track = 0\n",
    "        self.log = []\n",
    "\n",
    "        return self.state_encoder_dict, info_dict\n",
    "\n",
    "    def step(self, action_dict):\n",
    "\n",
    "        obs_dict, reward_dict, terminated_dict, info_dict = {}, {}, {}, {}\n",
    "        flag_dict = {}\n",
    "\n",
    "        # Update environemnt after actions\n",
    "        parsed_actions = []        \n",
    "        for syndicate_id, action in action_dict.items():\n",
    "            # update action map\n",
    "            self.action_map = self.action_map_creator(self.mm.market.syndicates[int(syndicate_id)],action)\n",
    "            parsed_ac2add = self.action_map\n",
    "            parsed_actions.append(parsed_ac2add)\n",
    "        \n",
    "        self.send_action2env(parsed_actions)\n",
    "\n",
    "        # Update broker_risk_events, broker_premium_events, broker_claim_events, event_handler, market manager\n",
    "        \"\"\"self.broker_premium_events = EventGenerator(self.risk_model_configs).generate_premium_events(self.brokers, self.timestep)\n",
    "        self.event_handler.add_premium_events(self.broker_premium_events)\n",
    "        for i in range(len(self.catastrophe_events)):\n",
    "            if self.catastrophe_events[i].risk_start_time == self.timestep:\n",
    "                self.broker_claim_events = EventGenerator(self.risk_model_configs).generate_claim_events(self.brokers, self.timestep)\n",
    "                self.event_handler.add_claim_events(self.broker_claim_events)\n",
    "        self.mm.update_premium_events(self.broker_premium_events, self.event_handler)\n",
    "        self.mm.update_claim_events(self.broker_claim_events, self.event_handler)\"\"\"\n",
    "\n",
    "        \n",
    "        self.mm.market = self.mm.evolve(self.dt)\n",
    "        print(self.mm.market.syndicates[0].current_capital_category)\n",
    "        print(self.mm.market.syndicates[1].current_capital_category)\n",
    "        print(self.mm.market.syndicates[2].current_capital_category)\n",
    "        self.timestep += 1\n",
    "\n",
    "        # Compute rewards and get next observation\n",
    "        for syndicate_id, action in action_dict.items():\n",
    "            reward_dict[syndicate_id] = self.compute_reward(action, syndicate_id)\n",
    "            obs_dict[syndicate_id]= self.state_encoder(syndicate_id)\n",
    "            info_dict[syndicate_id] = {}\n",
    "            flag_dict[syndicate_id] = False\n",
    "            terminated_dict[syndicate_id] = self.check_termination(syndicate_id)\n",
    "            if terminated_dict[syndicate_id]:\n",
    "                self.dones.add(i)\n",
    "        # Update plot \n",
    "        self.draw2file(self.mm.market)\n",
    "\n",
    "        # All done termination check\n",
    "        all_terminated = True\n",
    "        for _, syndicate_terminated in terminated_dict.items():\n",
    "            if syndicate_terminated is False:\n",
    "                all_terminated = False\n",
    "                break\n",
    "        \n",
    "        terminated_dict[\"__all__\"] = all_terminated\n",
    "        flag_dict[\"__all__\"] = all_terminated\n",
    "\n",
    "        return obs_dict, reward_dict, terminated_dict, flag_dict, info_dict\n",
    "\n",
    "    def check_termination(self, syndicate_id):\n",
    "\n",
    "        # Update per syndicate status, True-active in market, False-exit market becuase of no contract or bankruptcy\n",
    "        market = self.mm.market\n",
    "        sy = market.syndicates[int(syndicate_id)] \n",
    "\n",
    "        # The simulation is done when syndicates exit or bankrupt or reach the maximum time step\n",
    "        if self.timestep >= self.maxstep:\n",
    "            terminated = True\n",
    "        else:\n",
    "            terminated = False\n",
    "\n",
    "        return terminated\n",
    "\n",
    "    def compute_reward(self, action, syndicate_id):\n",
    "\n",
    "        market = self.mm.market\n",
    "        # calculate reward function\n",
    "        r = [0.0] * 4\n",
    "\n",
    "        # For each insurable risk being accepted +1 or refused -1\n",
    "        if(self.timestep <= self.maxstep):\n",
    "            for broker_id in range(len(market.brokers)):\n",
    "                for risk in range(len(market.brokers[broker_id].risks)):\n",
    "                    for contract in range(len(market.brokers[broker_id].underwritten_contracts)):\n",
    "                        if market.brokers[broker_id].risks[risk][\"risk_id\"] == market.brokers[broker_id].underwritten_contracts[contract][\"risk_id\"]:\n",
    "                            r[0] += 1\n",
    "                        else:\n",
    "                            r[0] -= 1\n",
    "\n",
    "        # For each claim being paied +1 or refused -1\n",
    "        if(self.timestep <= self.maxstep):\n",
    "            for claim in range(len(market.syndicates[int(syndicate_id)].paid_claim)):\n",
    "                if market.syndicate[syndicate_id].paid_claim[claim][\"status\"] == True:\n",
    "                    r[1] += 1\n",
    "                else:\n",
    "                    r[1] -= 1\n",
    "\n",
    "        # Profit and Bankruptcy       \n",
    "        if(self.timestep <= self.maxstep):\n",
    "            initial_capital = market.syndicates[int(syndicate_id)].initial_capital\n",
    "            current_capital = market.syndicates[int(syndicate_id)].current_capital\n",
    "            r[2] += current_capital - initial_capital\n",
    "            if (current_capital - initial_capital) < 0:\n",
    "                r[3] -= 10000\n",
    "\n",
    "        # Sum reward\n",
    "        reward = 0.0\n",
    "        reward += np.sum(r)\n",
    "\n",
    "        return reward     \n",
    "\n",
    "    def send_action2env(self, parsed_actions):               \n",
    "            \n",
    "        # Apply action\n",
    "        if len(parsed_actions) > 0:\n",
    "            self.mm.receive_actions(actions=parsed_actions) \n",
    "    \n",
    "    def state_encoder(self, syndicate_id):\n",
    "        \n",
    "        ### Observation Space:             \n",
    "        obs = []\n",
    "        for risk in range(len(broker_risk_events)):\n",
    "            if broker_risk_events[risk].risk_start_time == self.timestep+1:\n",
    "                # Catastrophe risk category and risk value\n",
    "                obs.append(broker_risk_events[risk].risk_category)\n",
    "                obs.append(broker_risk_events[risk].risk_value)\n",
    "        \n",
    "        # Syndicates status current capital in \n",
    "        market = self.mm.market\n",
    "        for num in range(len(market.syndicates[int(syndicate_id)].current_capital_category)):\n",
    "            obs.append(market.syndicates[int(syndicate_id)].current_capital_category[num])\n",
    "            \n",
    "        return obs\n",
    "\n",
    "    def action_map_creator(self, syndicate, line_size):\n",
    "\n",
    "        action_map = None\n",
    "        for risk in range(len(broker_risk_events)):\n",
    "            if broker_risk_events[risk].risk_start_time == self.timestep+1:\n",
    "                action_map = Action(syndicate.syndicate_id, line_size, broker_risk_events[risk].risk_id, broker_risk_events[risk].broker_id)\n",
    "       \n",
    "        return action_map\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a013d49-4182-43a5-8317-3e44e174373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k2472543/Library/Python/3.8/lib/python/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/Users/k2472543/Library/Python/3.8/lib/python/site-packages/ray/rllib/algorithms/algorithm.py:483: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/Users/k2472543/Library/Python/3.8/lib/python/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/k2472543/Library/Python/3.8/lib/python/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/Users/k2472543/Library/Python/3.8/lib/python/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-03-12 17:34:19,400\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[36m(RolloutWorker pid=24930)\u001b[0m /Users/k2472543/Library/Python/3.8/lib/python/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=24930)\u001b[0m   gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[36m(RolloutWorker pid=24930)\u001b[0m /Users/k2472543/Library/Python/3.8/lib/python/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[36m(RolloutWorker pid=24930)\u001b[0m   logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[36m(RolloutWorker pid=24928)\u001b[0m 2024-03-12 17:34:21,982\tWARNING env.py:298 -- Your MultiAgentEnv <MultiAgentBasedModel instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__()` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "/Users/k2472543/Library/Python/3.8/lib/python/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/Users/k2472543/Library/Python/3.8/lib/python/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "2024-03-12 17:34:22,604\tWARNING env.py:298 -- Your MultiAgentEnv <MultiAgentBasedModel instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__()` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "2024-03-12 17:34:22,822\tWARNING util.py:62 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.6673785], dtype=float32), '1': array([0.73644173], dtype=float32), '2': array([0.5584881], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.782269], dtype=float32), '1': array([0.57503945], dtype=float32), '2': array([0.7523751], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.78865504], dtype=float32), '1': array([0.8569308], dtype=float32), '2': array([0.9], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.7308247], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.8606558], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.9], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.5], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.55552465], dtype=float32), '1': array([0.9], dtype=float32), '2': array([0.74920964], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.75775427], dtype=float32), '1': array([0.79758996], dtype=float32), '2': array([0.5], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.6174724], dtype=float32), '1': array([0.9], dtype=float32), '2': array([0.670544], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.7158004], dtype=float32), '1': array([0.9], dtype=float32), '2': array([0.77294195], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.5762125], dtype=float32), '1': array([0.61982906], dtype=float32), '2': array([0.5438673], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.68764466], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.7312821], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.88827074], dtype=float32), '1': array([0.8332422], dtype=float32), '2': array([0.6397832], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.679654], dtype=float32), '1': array([0.72118795], dtype=float32), '2': array([0.7904166], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.72746056], dtype=float32), '1': array([0.6871884], dtype=float32), '2': array([0.75713533], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.9], dtype=float32), '1': array([0.7312051], dtype=float32), '2': array([0.5], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.5863248], dtype=float32), '1': array([0.6768819], dtype=float32), '2': array([0.6882521], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.51367813], dtype=float32), '1': array([0.9], dtype=float32), '2': array([0.63611215], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.6363955], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.5], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.9], dtype=float32), '1': array([0.88852966], dtype=float32), '2': array([0.56999934], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.77276415], dtype=float32), '1': array([0.87177944], dtype=float32), '2': array([0.9], dtype=float32)}\n",
      ".[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.7025856], dtype=float32), '1': array([0.6760069], dtype=float32), '2': array([0.5], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.8796062], dtype=float32), '1': array([0.7788827], dtype=float32), '2': array([0.7118812], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.5], dtype=float32), '1': array([0.9], dtype=float32), '2': array([0.9], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.9], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.8273573], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.83181274], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.6045433], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.9], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.8278456], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.75808406], dtype=float32), '1': array([0.5], dtype=float32), '2': array([0.76761603], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.61193913], dtype=float32), '1': array([0.72397256], dtype=float32), '2': array([0.6765455], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.8257069], dtype=float32), '1': array([0.5801109], dtype=float32), '2': array([0.5], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.54207015], dtype=float32), '1': array([0.73379445], dtype=float32), '2': array([0.5], dtype=float32)}\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2499000.0, 2500000.0, 2500000.0]\n",
      "[2500000.0, 2500000.0, 2500000.0, 2500000.0]\n",
      "{'0': array([0.50624514], dtype=float32), '1': array([0.7415151], dtype=float32), '2': array([0.5936018], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "### 6. Register environment and train the model\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray.tune.registry import register_env\n",
    "from ray import air, tune\n",
    "from ray.rllib.algorithms.ppo import PPO\n",
    "from ipywidgets import IntProgress\n",
    "from gym.spaces import Box\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.rllib.examples.policy.random_policy import RandomPolicy\n",
    "\n",
    "insurance_args = {\"sim_args\": sim_args,\n",
    "    \"manager_args\": manager_args,\n",
    "    \"brokers\": brokers,\n",
    "    \"syndicates\": syndicates,\n",
    "    \"reinsurancefirms\": reinsurancefirms,\n",
    "    \"shareholders\": shareholders,\n",
    "    \"catastrophes\": catastrophes,\n",
    "    \"risk_model_configs\": risk_model_configs,\n",
    "    \"with_reinsurance\": with_reinsurance,\n",
    "    \"num_risk_models\": num_risk_models}\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return MultiAgentBasedModel(**env_config)\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "        # agent0 -> main0\n",
    "        # agent1 -> main1\n",
    "        return f\"main{agent_id[-1]}\"\n",
    "\n",
    "def ppo_trainer_creator(insurance_args):\n",
    "    \n",
    "    config = {\n",
    "        \"env\": \"SpecialtyInsuranceMarket-validation\",\n",
    "        \"framework\": \"tf\",\n",
    "        \"multi_agent\": {\"policies\":{\n",
    "                # The Policy we are actually learning.\n",
    "                \"main0\": PolicySpec(\n",
    "                    observation_space=gym.spaces.Box(low=np.array([-1000000,-1000000,-1000000,-1000000,-1000000,-1000000]), \n",
    "                                                     high=np.array([1000000,1000000,3000000,3000000,3000000,3000000]), dtype = np.float32),\n",
    "                    action_space=gym.spaces.Box(0.5, 0.9, dtype = np.float32)\n",
    "                ),\n",
    "                \"main1\": PolicySpec(\n",
    "                    observation_space=gym.spaces.Box(low=np.array([-1000000,-1000000,-1000000,-1000000,-1000000,-1000000]), \n",
    "                                                     high=np.array([1000000,1000000,3000000,3000000,3000000,3000000]), dtype = np.float32),\n",
    "                    action_space=gym.spaces.Box(0.5, 0.9, dtype = np.float32)\n",
    "                ),\n",
    "                \"random\": PolicySpec(policy_class=RandomPolicy),\n",
    "            }, \n",
    "                        \"policy_mapping_fn\": policy_mapping_fn,\n",
    "                        \"policies_to_train\":[\"main0\"],\n",
    "        },\n",
    "        \"observation_space\": gym.spaces.Box(low=np.array([-1000000,-1000000,-1000000,-1000000,-1000000,-1000000]), \n",
    "                                            high=np.array([1000000,1000000,3000000,3000000,3000000,3000000]), dtype = np.float32),\n",
    "        \"action_space\": gym.spaces.Box(0.5, 0.9, dtype = np.float32),\n",
    "        \"env_config\": insurance_args,\n",
    "        \"evaluation_interval\": 2,\n",
    "        \"evaluation_duration\": 20,\n",
    "    }\n",
    "    \n",
    "    trainer = PPO(config=config)\n",
    "    return trainer\n",
    "\n",
    "# Folder for recording\n",
    "top_dir = \"noreinsurance_\" + \"_model_\" + str(num_risk_models)\n",
    "\n",
    "# Register environment\n",
    "register_env(\"SpecialtyInsuranceMarket-validation\", env_creator)\n",
    "\n",
    "# The number of training iteration for the RL agent\n",
    "num_training = 2\n",
    "\n",
    "trainer = ppo_trainer_creator(insurance_args)\n",
    "# Number of training iterations\n",
    "\n",
    "\"\"\"for n in range(num_training):\n",
    "    # Create a path to store the trained agent for each iteration\n",
    "    model_filepath = f\"{top_dir}/{str(n)}/saved_models\"\n",
    "        \n",
    "    num_episode = 10\n",
    "\n",
    "    # A training iteration includes parallel sample collection by the environment workers \n",
    "    # as well as loss calculation on the collected batch and a model update.\n",
    "\n",
    "    bar = IntProgress(min=0, max=num_episode)\n",
    "    display(bar)\n",
    "    list_mean_rewards = []\n",
    "    list_min_rewards = []\n",
    "    list_max_rewards = []\n",
    "    list_train_step = []\n",
    "\n",
    "    for i in range(num_episode):\n",
    "        trainer.train()     \n",
    "        print(\"Progress:\", i+1, \"/\", num_episode, end=\"\\r\")\n",
    "        bar.value += 1\n",
    "        if (i+1) % 2 == 0:\n",
    "            list_mean_rewards.append(trainer.evaluation_metrics[\"evaluation\"][\"episode_reward_mean\"])\n",
    "            list_min_rewards.append(trainer.evaluation_metrics[\"evaluation\"][\"episode_reward_min\"])\n",
    "            list_max_rewards.append(trainer.evaluation_metrics[\"evaluation\"][\"episode_reward_max\"])\n",
    "            list_train_step.append(i+1)\n",
    "        if i % 10 == 0:\n",
    "            trainer.save(model_filepath)\"\"\"\n",
    "        \n",
    "    \n",
    "\n",
    "# Can be used for game model\n",
    "env = MultiAgentBasedModel(**insurance_args)\n",
    "    \n",
    "total_steps = 0\n",
    "terminated_dict = {\"__all__\": False}\n",
    "    \n",
    "obs_dict, info_dict = env.reset()\n",
    "\n",
    "while not terminated_dict[\"__all__\"]:\n",
    "    if total_steps % 20 == 0: print(\".\", end=\"\")\n",
    "        \n",
    "    action_dict = trainer.compute_actions(obs_dict)  \n",
    "    total_steps += 1\n",
    "        \n",
    "    obs_dict, reward_dict, terminated_dict, flag_dict, info_dict = env.step(action_dict)\n",
    "    print(action_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33b840-6a04-40b9-ac1c-66f915f14bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. Test the trained model performance\n",
    "\n",
    "def trainer_restore(self, top_dir, n):\n",
    "    if n <= 9:\n",
    "        path0 = top_dir\n",
    "        path1 = str(n-1)\n",
    "        path2 = \"saved_models\"\n",
    "        path3 = \"checkpoint_\"+str(0)+str(0)+str(0)+str(0)+str(0)+str(n)\n",
    "        path4 = \"rllib_checkpoint.json\"\n",
    "    elif 9 < n <= 99:\n",
    "        path0 = top_dir\n",
    "        path1 = str(n-1)\n",
    "        path2 = \"saved_models\"\n",
    "        path3 = \"checkpoint_\"+str(0)+str(0)+str(0)+str(0)+str(n)\n",
    "        path4 = \"rllib_checkpoint.json\"\n",
    "    elif 99 < n <= 999:\n",
    "        path0 = top_dir\n",
    "        path1 = str(n-1)\n",
    "        path2 = \"saved_models\"\n",
    "        path3 = \"checkpoint_\"+str(0)+str(0)+str(0)+str(n)\n",
    "        path4 = \"rllib_checkpoint.json\"\n",
    "\n",
    "    # Join various path components\n",
    "    self.trainer.restore(os.path.join(path0, path1, path2, path3, path4))\n",
    "\n",
    "insurance_args = {\"sim_args\": sim_args,\n",
    "        \"manager_args\": manager_args,\n",
    "        \"brokers\": brokers,\n",
    "        \"syndicates\": syndicates,\n",
    "        \"reinsurancefirms\": reinsurancefirms,\n",
    "        \"shareholders\": shareholders,\n",
    "        \"catastrophes\": catastrophes,\n",
    "        \"risk_model_configs\": risk_model_configs,\n",
    "         \"with_reinsurance\": with_reinsurance,\n",
    "        \"num_risk_models\": num_risk_models}\n",
    "\n",
    "validation_episodes = 1\n",
    "all_rewards = {}\n",
    "        \n",
    "for epi in range(validation_episodes):\n",
    "    env = MultiAgentBasedModel(**insurance_args)\n",
    "    \n",
    "    print(f\"\\nepisode: {epi} | \")\n",
    "    total_steps = 0\n",
    "    terminated_dict = {\"__all__\": False}\n",
    "    all_rewards[epi] = {}\n",
    "    \n",
    "    obs_dict, info_dict = env.reset()\n",
    "    \n",
    "    while not terminated_dict[\"__all__\"]:\n",
    "        if total_steps % 20 == 0: print(\".\", end=\"\")\n",
    "        \n",
    "        action_dict = trainer.compute_actions(obs_dict)  \n",
    "        total_steps += 1\n",
    "        \n",
    "        obs_dict, reward_dict, terminated_dict, flag_dict, info_dict = env.step(action_dict)\n",
    "        print(total_steps)\n",
    "        print(action_dict)\n",
    "        for k, v in reward_dict.items():\n",
    "            if k not in all_rewards[epi]:\n",
    "                all_rewards[epi][k] = [v]\n",
    "            else:\n",
    "                all_rewards[epi][k].append(v)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main function run the simulation, two syndicates will be chosen to compete for the leader position\n",
    "from manager.ai_model.runner import AIRunner\n",
    "from manager.game_model.runner import GameRunner\n",
    "\n",
    "model = 0\n",
    "if model == 0: \n",
    "    runner = AIRunner(sim_args, manager_args, brokers, syndicates, reinsurancefirms, shareholders, catastrophes, risk_model_configs, with_reinsurance, num_risk_models)\n",
    "elif model == 1:\n",
    "    runner = GameRunner(sim_args, manager_args, brokers, syndicates, reinsurancefirms, shareholders, catastrophes, risk_model_configs, with_reinsurance, num_risk_models)\n",
    "runner.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment.event.add_catastrophe import AddCatastropheEvent\n",
    "from environment.event.add_attritionalloss import AddAttritionalLossEvent\n",
    "from environment.event.add_risk import AddRiskEvent\n",
    "from environment.event.add_premium import AddPremiumEvent\n",
    "from environment.event.add_claim import AddClaimEvent\n",
    "from environment.event_generator import EventGenerator\n",
    "from manager.event_handler import EventHandler\n",
    "from environment.market import NoReinsurance_RiskOne\n",
    "import numpy as np\n",
    "\n",
    "catastrophe_events = EventGenerator(risk_model_configs).generate_catastrophe_events(catastrophes)\n",
    "attritional_loss_events = EventGenerator(risk_model_configs).generate_attritional_loss_events(sim_args, catastrophes)\n",
    "broker_risk_events = broker_risk_events\n",
    "broker_premium_events = []\n",
    "broker_claim_events = []\n",
    "time = 0\n",
    "market = NoReinsurance_RiskOne(time, sim_args[\"max_time\"], manager_args, brokers, syndicates, \n",
    "                               shareholders, catastrophes, risk_model_configs, broker_risk_events)\n",
    "event_handler = EventHandler(sim_args[\"max_time\"], broker_risk_events)\n",
    "\n",
    "step_time = 1\n",
    "market_start_time = market.time\n",
    "market_end_time = market.time + step_time\n",
    "\n",
    "#upcoming_catastrophe = [\n",
    "            #e.risk_id for e in event_handler.upcoming_catastrophe.values() if isinstance(e, AddCatastropheEvent)\n",
    "        #]\n",
    "#upcoming_attritional_loss = [\n",
    "            #e.risk_id for e in event_handler.upcoming_attritional_loss.values() if isinstance(e, AddAttritionalLossEvent)\n",
    "        #]\n",
    "upcoming_broker_risk = [\n",
    "            e.risk_id for e in event_handler.upcoming_broker_risk.values() if isinstance(e, AddRiskEvent)\n",
    "        ]\n",
    "#upcoming_broker_premium = [\n",
    "            #e.risk_id for e in event_handler.upcoming_broker_premium.values() if isinstance(e, AddPremiumEvent)\n",
    "        #]\n",
    "#upcoming_broker_claim = [\n",
    "            #e.risk_id for e in event_handler.upcoming_broker_claim.values() if isinstance(e, AddClaimEvent)\n",
    "        #]\n",
    "step_time = 1\n",
    "market = event_handler.forward(market, step_time)\n",
    "\n",
    "#newly_added_catastrophe_events = {\n",
    "#            e.risk_id: e.risk_start_time\n",
    "#            for e in event_handler.completed_catastrophe.values()\n",
    "#            if isinstance(e, AddCatastropheEvent) and (e.risk_id in upcoming_catastrophe)\n",
    "#        }\n",
    "\n",
    "#newly_added_attritional_loss_events = {\n",
    "#            e.risk_id: e.risk_start_time\n",
    "#            for e in event_handler.completed_attritional_loss.values()\n",
    "#            if isinstance(e, AddAttritionalLossEvent) and (e.risk_id in upcoming_attritional_loss)\n",
    "#        }\n",
    "\n",
    "newly_added_broker_risk_events = {\n",
    "            e.risk_id: e.risk_start_time\n",
    "            for e in event_handler.completed_broker_risk.values()\n",
    "            if isinstance(e, AddRiskEvent) and (e.risk_id in upcoming_broker_risk)\n",
    "        }\n",
    "\n",
    "#newly_added_broker_premium_events = {\n",
    "#            e.risk_id: e.risk_start_time\n",
    "#            for e in event_handler.completed_broker_premium.values()\n",
    "#            if isinstance(e, AddPremiumEvent) and (e.risk_id in upcoming_broker_premium)\n",
    "#        }\n",
    "\n",
    "#newly_added_broker_claim_events = {\n",
    "#            e.risk_id: e.risk_start_time\n",
    "#            for e in event_handler.completed_broker_claim.values()\n",
    "#            if isinstance(e, AddClaimEvent) and (e.risk_id in upcoming_broker_claim)\n",
    "#        }\n",
    "\n",
    "#catastrophe_event_start_times = np.array(\n",
    "#            [\n",
    "#                newly_added_catastrophe_events.get(risk_id)\n",
    "#                for risk_id in upcoming_catastrophe\n",
    "#                if newly_added_catastrophe_events.get(risk_id) != None\n",
    "#            ]\n",
    "#        )\n",
    "\n",
    "#attritional_loss_event_start_times = np.array(\n",
    "#            [\n",
    "#                newly_added_attritional_loss_events.get(risk_id)\n",
    "#                for risk_id in upcoming_attritional_loss\n",
    "#                if newly_added_attritional_loss_events.get(risk_id) != None\n",
    "#            ]\n",
    "#        )\n",
    "\n",
    "broker_risk_event_start_times = np.array(\n",
    "            [\n",
    "                newly_added_broker_risk_events.get(risk_id)\n",
    "                for risk_id in upcoming_broker_risk\n",
    "                if newly_added_broker_risk_events.get(risk_id) != None\n",
    "            ]\n",
    "        )\n",
    "\n",
    "#broker_premium_event_start_times = np.array(\n",
    "#            [\n",
    "#                newly_added_broker_premium_events.get(risk_id)\n",
    "#                for risk_id in upcoming_broker_premium\n",
    "#                if newly_added_broker_premium_events.get(risk_id) != None\n",
    "#            ]\n",
    "#        )\n",
    "\n",
    "#broker_claim_event_start_times = np.array(\n",
    "#            [\n",
    "#                newly_added_broker_claim_events.get(risk_id)\n",
    "#                for risk_id in upcoming_broker_claim\n",
    "#                if newly_added_broker_claim_events.get(risk_id) != None\n",
    "#            ]\n",
    "#        )\n",
    "\n",
    "#event_start_times = np.concatenate((catastrophe_event_start_times,\n",
    "#                                    attritional_loss_event_start_times,\n",
    "#                                    broker_risk_event_start_times,\n",
    "#                                    broker_premium_event_start_times,\n",
    "#                                    broker_claim_event_start_times))\n",
    "\n",
    "sorted_unique_start_times = np.sort(np.unique(broker_risk_event_start_times))\n",
    "\n",
    "for start_time in sorted_unique_start_times:\n",
    "    starting_broker_risk = None\n",
    "    for i in range(len(broker_risk_events)):\n",
    "        if broker_risk_events[i].risk_start_time == start_time:\n",
    "            starting_broker_risk = broker_risk_events[i]\n",
    "    proceed_time = market_end_time - start_time\n",
    "    if proceed_time == 0:\n",
    "        continue\n",
    "print(starting_broker_risk)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ddd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
